===========================================================================================================
===>>> Почему иногда на сигмоиде, когда мы застреваем веса меняют направление (-)
(см. в тетради гипотезу) + проверить:
СНАЧАЛА ПОДКЛЮЧИТЬ:
- сделать проект мавеновским
- log4j чтобы можно было писать отладочную инфу

после кажой эпохи для каждого веса строить график зависимости общей ошибки от каждого веса в его ближайшей окресности
так же выводить сообщение о смене знака дельты этого веса
Хочеться подтвердить теорию
Если она подтверждается то как тогда будет работать алгоритм Rprop ?



===========================================================================================================
===>>> Почему всё-таки мы застреваем в сигмоиде в 90% случаях, а в апроксимации гиперболического тангенса не застреваем вообще (-)
+ оказывается и в тангенсе тож застреваем в 50% случаев!!!!



===========================================================================================================
===>>> Почему если во время не остановиться то будет такая картина:
Input: |  0.0000000000||  0.0000000000| => |  0.0003386510|
Input: |  1.0000000000||  0.0000000000| => |  0.9601600000|
Input: |  0.0000000000||  1.0000000000| => |  0.5645020307|
Input: |  1.0000000000||  1.0000000000| => |  0.7013795846|
----------------------
| Epoch: 36420; full relative error: 0.21245007280056594; current error: 0.3415895716434445; min error: 0.0016596983009610805; TREND: !!!ascent!!!
----------------------
как мы проскакивыем минимум? Вылетаем из него из-за большого шага?
Возможно  по причине нарисованной в тетради (см. тетрадь)
Проверить после реализации Rprop



===========================================================================================================
===>>> Изменить подход остановки обучения (-)
Если нет проверочных сэмплов:
- например может гонять определённое время и обновлять минимальное значение + запоминать в нём топологию
	спустя это время выдавать топологию по минимальному значению

Если есть проверочные сэмплы:
- прогнать проверочные сэмплы и напрмер оценить % провальных, например если у нас используется граничный фильтр на выходе каждого нейрона - пропускаем
	через неё и если хоть один выход отличается то результат провальный