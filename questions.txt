===========================================================================================================
===>>> Почему иногда на сигмоиде, когда мы застреваем веса меняют направление (-)
(см. в тетради гипотезу) + проверить:
СНАЧАЛА ПОДКЛЮЧИТЬ:
- сделать проект мавеновским (+)
- log4j чтобы можно было писать отладочную инфу (+)

после кажой эпохи для каждого веса строить график зависимости общей ошибки от каждого веса в его ближайшей окресности
так же выводить сообщение о смене знака дельты этого веса
Хочеться подтвердить теорию
Если она подтверждается то как тогда будет работать алгоритм Rprop ?
Ответ см. Caution: на стр. 95.


===========================================================================================================
===>>> Почему всё-таки мы застреваем в сигмоиде в 90% случаях, а в апроксимации гиперболического тангенса не застреваем вообще (-)
+ оказывается и в тангенсе тож застреваем в 50% случаев!!!!



===========================================================================================================
===>>> Почему если во время не остановиться то будет такая картина: (-)
08-Dec-2017 16:55:03,387 MSK DEBUG - Input: |  0.0000000000||  0.0000000000| => | -0.0019561600|
08-Dec-2017 16:55:03,387 MSK DEBUG - Input: |  1.0000000000||  0.0000000000| => |  0.9601600000|
08-Dec-2017 16:55:03,387 MSK DEBUG - Input: |  0.0000000000||  1.0000000000| => |  0.9601600000|
08-Dec-2017 16:55:03,387 MSK DEBUG - Input: |  1.0000000000||  1.0000000000| => |  0.9601600000|
08-Dec-2017 16:55:03,387 MSK DEBUG - | Epoch: 113422; full relative error: 0.17786992794355758; current error: 0.46254275168093817; min error: 0.1301446729460685; TREND: !!!ascent!!!
08-Dec-2017 16:55:03,387 MSK DEBUG - Input: |  0.0000000000||  0.0000000000| => | -0.0018927466|
08-Dec-2017 16:55:03,387 MSK DEBUG - Input: |  1.0000000000||  0.0000000000| => |  0.9601600000|
08-Dec-2017 16:55:03,387 MSK DEBUG - Input: |  0.0000000000||  1.0000000000| => |  0.9601600000|
08-Dec-2017 16:55:03,387 MSK DEBUG - Input: |  1.0000000000||  1.0000000000| => | -0.0546292631|
08-Dec-2017 16:55:03,387 MSK DEBUG - | Epoch: 113423; full relative error: 0.06219916338586815; current error: 0.0030811950370851194; min error: 0.0030811950370851194; TREND: decent
08-Dec-2017 16:55:03,387 MSK DEBUG - Input: |  0.0000000000||  0.0000000000| => | -0.0020133985|
08-Dec-2017 16:55:03,387 MSK DEBUG - Input: |  1.0000000000||  0.0000000000| => |  0.9601600000|
08-Dec-2017 16:55:03,387 MSK DEBUG - Input: |  0.0000000000||  1.0000000000| => |  0.0165653572|
08-Dec-2017 16:55:03,387 MSK DEBUG - Input: |  1.0000000000||  1.0000000000| => |  0.8798056398|
08-Dec-2017 16:55:03,387 MSK DEBUG - | Epoch: 113424; full relative error: 0.26356752760852636; current error: 0.8713964698755947; min error: 0.0030811950370851194; TREND: !!!ascent!!!
как мы проскакивыем минимум? Вылетаем из него из-за большого шага?
Возможно  по причине нарисованной в тетради (см. тетрадь)
Проверить после реализации Rprop




===========================================================================================================
===>>> Изменить подход остановки обучения (-)
Если нет проверочных сэмплов:
- например может гонять определённое время и обновлять минимальное значение + запоминать в нём топологию
	спустя это время выдавать топологию по минимальному значению

Если есть проверочные сэмплы:
- прогнать проверочные сэмплы и напрмер оценить % провальных, например если у нас используется граничный фильтр на выходе каждого нейрона - пропускаем
	через неё и если хоть один выход отличается то результат провальный


============================================================================================================
===>>> Новый вид NN, способный различать капчи, по структуре схож с мозгом
https://www.vicarious.com/2017/10/26/common-sense-cortex-and-captcha/
https://github.com/vicariousinc/science_rcn
Так же код лежит на Я.ДИСК тут: Common Sense, Cortex, and CAPTCHA
Можно покурить, понять идею, реализовать на java например

















